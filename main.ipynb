{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe049db6",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "388977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ec822",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3419a494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1025, 14)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "      <td>1025.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.43</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.94</td>\n",
       "      <td>131.61</td>\n",
       "      <td>246.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.53</td>\n",
       "      <td>149.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.07</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.03</td>\n",
       "      <td>17.52</td>\n",
       "      <td>51.59</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>23.01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>211.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>132.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>130.00</td>\n",
       "      <td>240.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>152.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>140.00</td>\n",
       "      <td>275.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>166.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>200.00</td>\n",
       "      <td>564.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>202.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      sex       cp  trestbps     chol      fbs  restecg  \\\n",
       "count  1025.00  1025.00  1025.00   1025.00  1025.00  1025.00  1025.00   \n",
       "mean     54.43     0.70     0.94    131.61   246.00     0.15     0.53   \n",
       "std       9.07     0.46     1.03     17.52    51.59     0.36     0.53   \n",
       "min      29.00     0.00     0.00     94.00   126.00     0.00     0.00   \n",
       "25%      48.00     0.00     0.00    120.00   211.00     0.00     0.00   \n",
       "50%      56.00     1.00     1.00    130.00   240.00     0.00     1.00   \n",
       "75%      61.00     1.00     2.00    140.00   275.00     0.00     1.00   \n",
       "max      77.00     1.00     3.00    200.00   564.00     1.00     2.00   \n",
       "\n",
       "       thalach    exang  oldpeak    slope       ca     thal   target  \n",
       "count  1025.00  1025.00  1025.00  1025.00  1025.00  1025.00  1025.00  \n",
       "mean    149.11     0.34     1.07     1.39     0.75     2.32     0.51  \n",
       "std      23.01     0.47     1.18     0.62     1.03     0.62     0.50  \n",
       "min      71.00     0.00     0.00     0.00     0.00     0.00     0.00  \n",
       "25%     132.00     0.00     0.00     1.00     0.00     2.00     0.00  \n",
       "50%     152.00     0.00     0.80     1.00     0.00     2.00     1.00  \n",
       "75%     166.00     1.00     1.80     2.00     1.00     3.00     1.00  \n",
       "max     202.00     1.00     6.20     2.00     4.00     3.00     1.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values: 0\n",
      "Total duplicates: 723\n",
      "\n",
      "Column Names:\n",
      "['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "display(df.info())\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(df.describe().round(2))\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "display(df.isnull().sum())\n",
    "print(f\"Total missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Total duplicates: {df.duplicated().sum().sum()}\")\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0756caf1",
   "metadata": {},
   "source": [
    "# 2. ETL Process (Extract, Transform, Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "59567eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ETL PROCESS ===\n",
      "1. Data Quality Checks:\n",
      "   Initial shape: (1025, 14)\n",
      "   Missing values: 0\n",
      "2. Data Type Validation and Conversion:\n",
      "   Data type is correct\n",
      "3. Removed 723 duplicate rows\n",
      "4. Outlier Treatment:\n",
      "   Treated 91 outliers across all numerical columns\n",
      "5. Feature Engineering:\n",
      "   Created age groups and cholesterol categories\n",
      "\n",
      "Final ETL dataset shape: (302, 16)\n",
      "\n",
      "ETL Process Completed Successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>age_group</th>\n",
       "      <th>chol_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Borderline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Senior</td>\n",
       "      <td>Borderline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>Borderline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Elderly</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  52.0  1.0  0.0     125.0  212.0  0.0      1.0    168.0    0.0      1.0   \n",
       "1  53.0  1.0  0.0     140.0  203.0  0.0      0.0    155.0    1.0      3.1   \n",
       "2  70.0  1.0  0.0     145.0  174.0  0.0      1.0    125.0    1.0      2.6   \n",
       "3  61.0  1.0  0.0     148.0  203.0  0.0      1.0    161.0    0.0      0.0   \n",
       "4  62.0  0.0  0.0     138.0  294.0  0.0      1.0    106.0    0.0      1.9   \n",
       "\n",
       "   slope   ca  thal  target age_group chol_category  \n",
       "0    2.0  2.0   3.0     0.0    Senior    Borderline  \n",
       "1    0.0  0.0   3.0     0.0    Senior    Borderline  \n",
       "2    0.0  0.0   3.0     0.0   Elderly        Normal  \n",
       "3    2.0  1.0   3.0     0.0   Elderly    Borderline  \n",
       "4    1.0  2.5   2.0     0.0   Elderly          High  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ETL: Clean and transform data before loading into analysis\n",
    "def perform_etl(data):\n",
    "    \"\"\"\n",
    "    Perform ETL process: Extract, Transform, Load\n",
    "    Clean and transform data before loading into analysis\n",
    "    \"\"\"\n",
    "    print(\"=== ETL PROCESS ===\")\n",
    "    \n",
    "    # Create a copy for ETL\n",
    "    etl_data = data.copy()\n",
    "    \n",
    "    # Step 1: Data Quality Checks\n",
    "    print(\"1. Data Quality Checks:\")\n",
    "    print(f\"   Initial shape: {etl_data.shape}\")\n",
    "    print(f\"   Missing values: {etl_data.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Handle missing values if any\n",
    "    if etl_data.isnull().sum().sum() > 0:\n",
    "        # For numerical columns, fill with median\n",
    "        numerical_cols = etl_data.select_dtypes(include=[np.number]).columns\n",
    "        etl_data[numerical_cols] = etl_data[numerical_cols].fillna(etl_data[numerical_cols].median())\n",
    "        \n",
    "        # For categorical columns, fill with mode\n",
    "        categorical_cols = etl_data.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_cols:\n",
    "            etl_data[col] = etl_data[col].fillna(etl_data[col].mode()[0])\n",
    "    \n",
    "    # Step 2: Data Type Validation and Conversion\n",
    "    print(\"2. Data Type Validation and Conversion:\")\n",
    "    print(f\"   Data type is correct\")\n",
    "\n",
    "    # Check and convert data types if needed\n",
    "    for col in etl_data.columns:\n",
    "        if etl_data[col].dtype == 'object':\n",
    "            # Try to convert to numeric if possible\n",
    "            try:\n",
    "                etl_data[col] = pd.to_numeric(etl_data[col])\n",
    "                print(f\"Converted {col} to numeric\")\n",
    "            except:\n",
    "                print(f\"{col} remains as categorical\")\n",
    "\n",
    "    # Step 3: Remove duplicates\n",
    "    initial_rows = len(etl_data)\n",
    "    etl_data = etl_data.drop_duplicates()\n",
    "    print(f\"3. Removed {initial_rows - len(etl_data)} duplicate rows\")\n",
    "    \n",
    "    # Step 4: Outlier detection and treatment (using IQR method)\n",
    "    print(\"4. Outlier Treatment:\")\n",
    "    numerical_cols = etl_data.select_dtypes(include=[np.number]).columns\n",
    "    outlier_count = 0\n",
    "    \n",
    "    for col in numerical_cols:\n",
    "        Q1 = etl_data[col].quantile(0.25)\n",
    "        Q3 = etl_data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = etl_data[(etl_data[col] < lower_bound) | (etl_data[col] > upper_bound)]\n",
    "        outlier_count += len(outliers)\n",
    "        \n",
    "        # Cap outliers\n",
    "        etl_data[col] = np.where(etl_data[col] < lower_bound, lower_bound, etl_data[col])\n",
    "        etl_data[col] = np.where(etl_data[col] > upper_bound, upper_bound, etl_data[col])\n",
    "    \n",
    "    print(f\"   Treated {outlier_count} outliers across all numerical columns\")\n",
    "    \n",
    "    # Step 5: Feature Engineering\n",
    "    print(\"5. Feature Engineering:\")\n",
    "    print(\"   Created age groups and cholesterol categories\")\n",
    "    \n",
    "    # Create age groups\n",
    "    etl_data['age_group'] = pd.cut(etl_data['age'], bins=[0, 40, 50, 60, 100], labels=['Young', 'Middle-Aged', 'Senior', 'Elderly'])\n",
    "    \n",
    "    # Create cholesterol categories\n",
    "    etl_data['chol_category'] = pd.cut(etl_data['chol'], bins=[0, 200, 240, 1000], labels=['Normal', 'Borderline', 'High'])\n",
    "    \n",
    "    print(f\"\\nFinal ETL dataset shape: {etl_data.shape}\")\n",
    "\n",
    "    return etl_data\n",
    "\n",
    "# Perform ETL\n",
    "etl_processed_data = perform_etl(df)\n",
    "print(\"\\nETL Process Completed Successfully!\")\n",
    "\n",
    "display(etl_processed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e4923",
   "metadata": {},
   "source": [
    "# 3. ELT Process (Extract, Load, Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELT: Load raw data first, then transform within the sandbox\n",
    "def perform_elt(data):\n",
    "    \"\"\"\n",
    "    Perform ELT process: Extract, Load, Transform\n",
    "    Load raw data first, then transform within the sandbox\n",
    "    \"\"\"\n",
    "    print(\"\\n=== ELT PROCESS ===\")\n",
    "    \n",
    "    # Create a copy for ELT (simulating raw data loading)\n",
    "    elt_data = data.copy()\n",
    "    print(\"1. Raw data loaded into sandbox\")\n",
    "    print(f\"   Raw data shape: {elt_data.shape}\")\n",
    "    \n",
    "    # Step 2: Transform within the sandbox\n",
    "    print(\"2. Transforming data within sandbox:\")\n",
    "    \n",
    "    # Create a transformation log\n",
    "    transformation_log = []\n",
    "    \n",
    "    # Normalize numerical features\n",
    "    numerical_cols = elt_data.select_dtypes(include=[np.number]).columns\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Store original values for reference\n",
    "    for col in numerical_cols:\n",
    "        elt_data[f'{col}_original'] = elt_data[col]\n",
    "    \n",
    "    # Apply standardization\n",
    "    elt_data[numerical_cols] = scaler.fit_transform(elt_data[numerical_cols])\n",
    "    transformation_log.append(\"Standardized all numerical features\")\n",
    "    \n",
    "    # Create interaction features\n",
    "    elt_data['age_chol_interaction'] = elt_data['age'] * elt_data['chol']\n",
    "    elt_data['bp_chol_ratio'] = elt_data['trestbps'] / (elt_data['chol'] + 1)\n",
    "    transformation_log.append(\"Created interaction features: age_chol_interaction, bp_chol_ratio\")\n",
    "    \n",
    "    # Create categorical encodings\n",
    "    categorical_features = ['cp', 'restecg', 'slope', 'thal']\n",
    "    for feature in categorical_features:\n",
    "        if feature in elt_data.columns:\n",
    "            # One-hot encoding for low cardinality features\n",
    "            if elt_data[feature].nunique() <= 5:\n",
    "                dummies = pd.get_dummies(elt_data[feature], prefix=feature)\n",
    "                elt_data = pd.concat([elt_data, dummies], axis=1)\n",
    "                transformation_log.append(f\"One-hot encoded {feature}\")\n",
    "    \n",
    "    print(\"   Transformations applied:\")\n",
    "    for log in transformation_log:\n",
    "        print(f\"     - {log}\")\n",
    "    \n",
    "    print(f\"   Final ELT dataset shape: {elt_data.shape}\")\n",
    "    \n",
    "    return elt_data, transformation_log\n",
    "\n",
    "# Perform ELT\n",
    "elt_processed_data, transformations = perform_elt(df)\n",
    "print(\"\\nELT Process Completed Successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
